{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import warnings\n",
    "from google.oauth2.service_account import Credentials\n",
    "import gspread\n",
    "warnings.filterwarnings('ignore')\n",
    "import subprocess\n",
    "import schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_name_checked = ['Docked', 'Arrived', 'Counting', 'QC', 'Labeling',\n",
    "                    'Received', 'Putaway', 'Picking', 'Packing', 'AWB', 'RTS',\n",
    "                    'RT_picking', 'RT_putaway', 'Cyclecount', 'Print']  # , 'Testing']  # 新增新的種類\n",
    "\n",
    "cat_name = ['Docked', 'Arrived', 'Counting', 'QC', 'Labeling',\n",
    "            'Received', 'Putaway', 'Putaway_4floor', 'Picking', 'Packing',\n",
    "            'AWB', 'RTS', 'RT_picking', 'RT_picking_4floor', 'RT_putaway',\n",
    "            'RT_putaway_4floor', 'Cyclecount', 'Cyclecount_4floor', 'Print']  # , 'Testing']  # 新增新的種類\n",
    "\n",
    "\n",
    "type_dic = {\n",
    "    '碼頭收發': 'Docked',\n",
    "    '收貨': 'Arrived',\n",
    "    '進貨計數': 'Counting',\n",
    "    '品管': 'QC',\n",
    "    '貼標': 'Labeling',\n",
    "    '貴重驗收': 'Received',\n",
    "    '箱賣': 'Received',\n",
    "    '小驗': 'Received',\n",
    "    '大驗': 'Received',\n",
    "    '上架基架': 'Putaway',\n",
    "    '上架棧板': 'Putaway',\n",
    "    '上架基架_四樓': 'Putaway_4floor',\n",
    "    '上架棧板_四樓': 'Putaway_4floor',\n",
    "    '揀貨': 'Picking',\n",
    "    '包裝': 'Packing',\n",
    "    '出貨': 'AWB',\n",
    "    '退貨出貨': 'RTS',\n",
    "    '退貨包裝': 'RTS',\n",
    "    '退貨揀貨': 'RTS',\n",
    "    '移庫揀貨': 'RT_picking',\n",
    "    '移庫上架': 'RT_putaway',\n",
    "    '移庫揀貨_四樓': 'RT_picking_4floor',\n",
    "    '移庫上架_四樓': 'RT_putaway_4floor',\n",
    "    '盤點系統盤': 'Cyclecount',\n",
    "    '盤點系統盤_四樓': 'Cyclecount_4floor',\n",
    "    '印標': 'Print'\n",
    "    # '出貨5S': 'Testing'  # 直接加上新的種類即可\n",
    "}\n",
    "\n",
    "productivity_varable = {\n",
    "    'DL%': 1,\n",
    "    'DL % threshold': 0.6,\n",
    "    'Docked': 75,\n",
    "    'Arrived': 125,\n",
    "    'QC': 4638,\n",
    "    'Labeling': 850,\n",
    "    'Received': 800,\n",
    "    'Putaway': 65,\n",
    "    'Putaway_4floor': 65,\n",
    "    'Picking': 114,\n",
    "    'Packing': 143,\n",
    "    'Counting': 1000,\n",
    "    'AWB': 720,\n",
    "    'RTS': 300,\n",
    "    'RT_picking': 726,\n",
    "    'RT_putaway': 726,\n",
    "    'RT_picking_4floor': 726,\n",
    "    'RT_putaway_4floor': 726,\n",
    "    'Cyclecount': 850,\n",
    "    'Cyclecount_4floor': 850,\n",
    "    'Print': 200  # 20210716待確認\n",
    "    # 'Testing': 20  # 新增計算IPH指標\n",
    "}\n",
    "\n",
    "team_prod_dict = {\n",
    "    'Picking': '出貨控場',\n",
    "    'Packing': '出貨控場',\n",
    "    'AWB': '出貨控場',\n",
    "    'Arrived': '進貨控場',\n",
    "    'Counting': '進貨控場',\n",
    "    'QC': '進貨控場',\n",
    "    'Labeling': '進貨控場',\n",
    "    'Received': '進貨控場',\n",
    "    'Docked': '進貨控場',\n",
    "    'Print': '進貨控場',\n",
    "    'RT_picking': '移庫控場',\n",
    "    'RT_putaway': '移庫控場',\n",
    "    'RT_picking_4floor': '移庫控場_四樓',\n",
    "    'RT_putaway_4floor': '移庫控場_四樓',\n",
    "    'RTS': np.nan,\n",
    "    'Putaway': '移庫控場',\n",
    "    'Putaway_4floor': '移庫控場_四樓',\n",
    "    'Cyclecount': '盤點控場',\n",
    "    'Cyclecount_4floor': '盤點控場_四樓'\n",
    "    # 'Testing': '測試控場'  # 新增種類的控場\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gdoc_information():\n",
    "    def __init__(self):\n",
    "        self.SCOPES = \"\"\n",
    "        self.SAMPLE_SPREADSHEET_ID = \"\"\n",
    "        self.SAMPLE_RANGE_NAME = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_schema = gdoc_information()\n",
    "ppl_schema.SCOPES = 'https://docs.google.com/spreadsheets/d/1fKqmL3VS1aDjdeJR_MqLQwu9mdEjf_Ci8PV1QCp-M6Q'  # 不用每個月更改\n",
    "ppl_schema.SAMPLE_RANGE_NAME = '通訊錄'  # 抓整張工作表，之後再選要的欄位\n",
    "\n",
    "tag_gdoc = gdoc_information()\n",
    "tag_gdoc.SCOPES = 'https://docs.google.com/spreadsheets/d/1GUvKT8BxFsHLwgM2Jptmkpc0pIZMetoVtIUIet5UxB8/edit'  # 每個月要改網址\n",
    "\n",
    "docked_gdoc = gdoc_information()\n",
    "docked_gdoc.SCOPES = 'https://docs.google.com/spreadsheets/d/1eDn98UQJuJRKN-8IaQo6MDlOMCCV4HZE2Q8iSA6oXeE/edit'  # 不用每個月更改\n",
    "docked_gdoc.SAMPLE_RANGE_NAME = \"Filter\"\n",
    "\n",
    "print_gdoc = gdoc_information()\n",
    "print_gdoc.SCOPES = 'https://docs.google.com/spreadsheets/d/1uBRnzC3oNGKKjWt8kHRzYBj75ZDe-G9YW6wzPsR6fxY/edit'  # 不用每個月更改\n",
    "\n",
    "IB_gdoc = gdoc_information()\n",
    "IB_gdoc.SCOPES = 'https://docs.google.com/spreadsheets/d/1ttys51yVmai8MrQH-HlmbSJFlLITIcTjpXPEGQNEJQY/'  # 不用每個月更改\n",
    "IB_gdoc.SAMPLE_RANGE_NAME = \"IB\"\n",
    "\n",
    "WMS_gdoc = gdoc_information()\n",
    "WMS_gdoc.SCOPES = 'https://docs.google.com/spreadsheets/d/1ttys51yVmai8MrQH-HlmbSJFlLITIcTjpXPEGQNEJQY/'\n",
    "WMS_gdoc.SAMPLE_RANGE_NAME = \"WMS\"\n",
    "\n",
    "INV_gdoc = gdoc_information()\n",
    "INV_gdoc.SCOPES = 'https://docs.google.com/spreadsheets/d/1ttys51yVmai8MrQH-HlmbSJFlLITIcTjpXPEGQNEJQY/'\n",
    "INV_gdoc.SAMPLE_RANGE_NAME = \"INV\"\n",
    "\n",
    "Punch_gdoc = gdoc_information()\n",
    "Punch_gdoc.SCOPES = 'https://docs.google.com/spreadsheets/d/1ttys51yVmai8MrQH-HlmbSJFlLITIcTjpXPEGQNEJQY/'\n",
    "Punch_gdoc.SAMPLE_RANGE_NAME = \"punch\"\n",
    "\n",
    "OB_gdoc = gdoc_information()\n",
    "OB_gdoc.SCOPES = 'https://docs.google.com/spreadsheets/d/1ttys51yVmai8MrQH-HlmbSJFlLITIcTjpXPEGQNEJQY/'\n",
    "OB_gdoc.SAMPLE_RANGE_NAME = \"OB\"\n",
    "\n",
    "AWB_gdoc = gdoc_information()\n",
    "AWB_gdoc.SCOPES = 'https://docs.google.com/spreadsheets/d/1ttys51yVmai8MrQH-HlmbSJFlLITIcTjpXPEGQNEJQY/'\n",
    "AWB_gdoc.SAMPLE_RANGE_NAME = \"AWB\"\n",
    "\n",
    "Score_gdoc = gdoc_information()\n",
    "Score_gdoc.SCOPES = \"https://docs.google.com/spreadsheets/d/15BGIJYsV7onztRgBoji0D7ysKtmJiT2JozKmNGlzqSk/\"\n",
    "Score_gdoc.SAMPLE_RANGE_NAME = \"Daily Update\"\n",
    "\n",
    "No_data_gdoc = gdoc_information()\n",
    "No_data_gdoc.SCOPES = \"https://docs.google.com/spreadsheets/d/15BGIJYsV7onztRgBoji0D7ysKtmJiT2JozKmNGlzqSk/\"\n",
    "No_data_gdoc.SAMPLE_RANGE_NAME = \"No Data%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 1: 匯入打卡資料並進行前處理\n",
    "def read_punch_file(day, revise_station_name, gs):\n",
    "    '''\n",
    "    讀入站點打卡_for-attendance資料，進行整理\n",
    "    ----------------\n",
    "    Input:\n",
    "    1. path: 站點打卡路徑(punch_file_name)\n",
    "    2. revise_station_name: 要將站點進行參照的表格\n",
    "    2. type_dic: 字典，用於將站點打卡的中文站點轉換為英文\n",
    "    '''\n",
    "    punch_station = pd.read_excel(revise_station_name)  # 參照revise_station的工作表\n",
    "    punch_station['lookup'] = punch_station['Unnamed: 1']\\\n",
    "        .str.cat(punch_station['function_name'], sep=', ')\\\n",
    "        .str.cat(punch_station['function_role'], sep=', ')  # 將Unnamed, function_name, function_role三個欄位合再一起，作為參照\n",
    "    \n",
    "    punch_gsheet = gs.open_by_url(Punch_gdoc.SCOPES).worksheet(Punch_gdoc.SAMPLE_RANGE_NAME)\n",
    "    punch_raw_df = pd.DataFrame(punch_gsheet.get_all_records())\n",
    "        \n",
    "    punch_raw_df = (punch_raw_df[~pd.isnull(punch_raw_df['name'])])  # 只保留有名字的打卡記錄\n",
    "    punch_raw_df = punch_raw_df[punch_raw_df[\"date\"] == day]\n",
    "    punch_raw_df.drop_duplicates(inplace=True)  # 移除重複項目\n",
    "    \n",
    "\n",
    "    punch_raw_df['ID'] = punch_raw_df['ID'].str.lower()  # 將打卡員編轉為小寫，以利後續參照\n",
    "    punch_raw_df['type'] = punch_raw_df['function'].map(type_dic)  # 新增type，為type_dic的工作種類\n",
    "    punch_raw_df['type'] = punch_raw_df['type'].astype('str').replace('nan', np.nan)  # 將類別轉為字串格式，缺失值(不算Productivity的項目)為np.nan\n",
    "    punch_raw_df['min'] = punch_raw_df['min'].replace('', '0').astype('int')\n",
    "    punch_raw_df['hour'] = punch_raw_df['min'] / 60  # 新增小時欄位\n",
    "\n",
    "    punch_raw_df[\"created_time\"] = pd.to_datetime(punch_raw_df[\"created_time\"], errors='coerce')\n",
    "    punch_raw_df[\"end_time\"] = pd.to_datetime(punch_raw_df[\"end_time\"], errors='coerce')\n",
    "\n",
    "    punch_raw_df['lookup'] = punch_raw_df['']\\\n",
    "        .str.cat(punch_raw_df['function_name'], sep=', ')\\\n",
    "        .str.cat(punch_raw_df['function_role'], sep=', ')  # 將Unnamed, function_name, function_role三個欄位合再一起，作為參照\n",
    "    punch_raw_df.rename(columns={'date': 'create_date', 'ID': 'operator'})\n",
    "    punch_raw_df = punch_raw_df.merge(punch_station[['lookup', 'revised station']], on='lookup')\\\n",
    "                               .drop('lookup', axis=1)  # 參照完就把參照欄位lookup丟棄\n",
    "    punch_raw_df.sort_values('created_time', inplace=True)  # 之後merge_asof需要排序\n",
    "    punch_raw_df.reset_index(drop=True, inplace=True)\n",
    "    return punch_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 2: 匯入人力資料並進行前處理\n",
    "def read_human_data(gs):\n",
    "    '''\n",
    "    抓取「人力資料_schema」資料，並轉成後續需要的字典\n",
    "    1. name_id_dic: 姓名(key)與員編(value)\n",
    "    2. id_name_dic: 員編(key)與姓名(value)\n",
    "    3. pda_name_dic: PDA帳號(key)與姓名(value)\n",
    "    4. pda_id_dic: PDA帳號(key)與員編(value)\n",
    "    '''\n",
    "    \n",
    "    human_gsheet = gs.open_by_url(ppl_schema.SCOPES).worksheet(ppl_schema.SAMPLE_RANGE_NAME)\n",
    "    human_df = pd.DataFrame(human_gsheet.get_all_records(), columns=[\"WMS帳號\", \"公司\", \"PDA帳號\", \"worker_name\"])\n",
    "    human_df.columns = ['員編', '公司', 'PDA帳號', 'worker_name']\n",
    "    \n",
    "    id_name_dic = {str(x).lower(): y for x, y in zip(human_df['員編'], human_df['worker_name'])}\n",
    "    name_id_dic = {}\n",
    "    for key, value in id_name_dic.items():\n",
    "        if value not in name_id_dic.keys():\n",
    "            name_id_dic[value] = key\n",
    "    pda_name_dic = {str(x): y for x, y in zip(human_df['PDA帳號'], human_df['worker_name'])}\n",
    "    pda_id_dic = {str(x): str(y).lower() for x, y in zip(human_df['員編'], human_df['PDA帳號'])}\n",
    "    return name_id_dic, id_name_dic, pda_name_dic, pda_id_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 3: 將IB_production新增貼標、收發、印標資料\n",
    "def add_data_in_inb(time2, gs, day, month_fullname, inb_pics_file_path_new):\n",
    "    '''\n",
    "    1. 新增貼標到 inb_pics_file_path (IB_production) (2021/05)\n",
    "    2. 新增收發到 inb_pics_file_path (IB_production) (2021/05)\n",
    "    3. 新增印標到 inb_pics_file_path (IB_production) (2021/07 新增)\n",
    "    output: 更新inb_pics_file_path\n",
    "    '''\n",
    "    # 3-1 抓Google Sheet「人力資料schema」，存為ppl_schema_df(DataFrame)\n",
    "    ppl_schema_gsheet = gs.open_by_url(ppl_schema.SCOPES).worksheet(ppl_schema.SAMPLE_RANGE_NAME)\n",
    "    ppl_schema_df = pd.DataFrame(ppl_schema_gsheet.get_all_records(), columns=[\"WMS帳號\", \"PDA帳號\"])\n",
    "    ppl_schema_df.columns = ['員編', '貼標ID']\n",
    "    ppl_schema_df['貼標ID'] = ppl_schema_df['貼標ID'].astype(\"str\")\n",
    "    ppl_schema_df.dropna(inplace=True)\n",
    "    time3_1 = time.time()\n",
    "    print('Checkpoint 3-1 人力資料_schema SUCCEED    Spend {:.2f} seconds'.format(time3_1 - time2))\n",
    "\n",
    "    # 3-2 抓取貼標資料，在get_gdoc.get_tag_data中匯出excel，並存為tag_summary\n",
    "    tag_df = get_everyday_tag_data(day, gs)\n",
    "    tag_df = tag_df[[\"版標流水號\", \"貼標開始\", \"貼標人數(人)\", \"貼標ID\"]]\n",
    "    \n",
    "    wms_gsheet = gs.open_by_url(WMS_gdoc.SCOPES).worksheet(WMS_gdoc.SAMPLE_RANGE_NAME)\n",
    "    wms_label_df = pd.DataFrame(wms_gsheet.get_all_records()).rename(columns={\"_col0\": \"date\"})\n",
    "    wms_label_df = wms_label_df[wms_label_df[\"date\"] == day][['tracking_id', 'batch_qty']] # 抓取每個流水號每個batch有多少數量\n",
    "\n",
    "    tag_df = pd.merge(tag_df, wms_label_df, left_on='版標流水號', right_on='tracking_id') # 將每個貼標有多少個batch結合\n",
    "    tag_df[\"貼標ID\"] = tag_df[\"貼標ID\"].astype('str')\n",
    "    tag_df['貼標人數(人)'] = tag_df['貼標人數(人)'].astype(\"int\")\n",
    "    tag_df['員工作業PCS'] = tag_df['batch_qty'] / tag_df['貼標人數(人)']\n",
    "    \n",
    "    tag_summary = tag_df.groupby(['貼標開始', '貼標ID']).sum()\n",
    "    \n",
    "    tag_summary = tag_summary.reset_index()\n",
    "    tag_summary = tag_summary.merge(ppl_schema_df, left_on='貼標ID', right_on='貼標ID', how='left')  # 得到貼標的員編\n",
    "    tag_summary = tag_summary[tag_summary['員編'].notnull()]\n",
    "    tag_summary['type'] = 'Labeling'\n",
    "    tag_summary['box'] = 0  # 其他種類才用到box，貼標資料皆為0\n",
    "    tag_summary['orders'] = 0  # 其他種類才用到orders，貼標資料皆為0\n",
    "    tag_summary = tag_summary[['員編', 'type', '員工作業PCS', 'box', 'orders', '貼標開始']]\n",
    "    tag_summary.columns = ['operator', 'type', 'total_pcs', 'box', 'orders', 'inbound_date']  # 合併資料統一要這幾個欄位\n",
    "    tag_summary['inbound_date'] = pd.to_datetime(tag_summary['inbound_date'], errors='coerce')\n",
    "    print(tag_summary.head())\n",
    "    time3_2 = time.time()\n",
    "    print('Checkpoint 3-2 tag_summary SUCCEED        Spend {:.2f} seconds'.format(time3_2 - time3_1))\n",
    "    \n",
    "    # 3-3 抓取新增收發，並匯出excel，並存為docked_summary\n",
    "    docked_gsheet = gs.open_by_url(docked_gdoc.SCOPES).worksheet(docked_gdoc.SAMPLE_RANGE_NAME)\n",
    "    \n",
    "    docked_df = pd.DataFrame(docked_gsheet.get_all_records())\n",
    "    \n",
    "    docked_df['收發時間'] = pd.to_datetime(docked_df['收發時間'], errors='coerce')\n",
    "    docked_df.dropna(subset=[\"收發時間\"], axis=0, inplace=True)\n",
    "    docked_df[\"DATE\"] = docked_df[\"收發時間\"].apply(lambda x: x.day)\n",
    "    docked_df[\"HOUR\"] = docked_df[\"收發時間\"].apply(lambda x: x.hour)\n",
    "    \n",
    "    docked_df[\"keep\"] = docked_df[\"收發時間\"].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    docked_df = docked_df[docked_df[\"keep\"] == day]\n",
    "    docked_df = docked_df.drop(columns='keep')\n",
    "    \n",
    "    docked_path = 'tmp_output/docked_raw/docked_raw_{}.xlsx'.format(month_fullname)\n",
    "    docked_df.to_excel(docked_path, index=False)\n",
    "\n",
    "    docked_df.columns = ['員編', 'INbound ID', 'QTY', '收發時間', 'DATE', 'HOUR']\n",
    "    docked_df['員編'] = docked_df['員編'].astype('str')\n",
    "    docked_summary = docked_df.groupby(['收發時間', '員編'])['INbound ID'].count()\n",
    "    docked_summary = docked_summary.reset_index()\n",
    "    \n",
    "    # Mapping 人力資料 schema 五碼變SP\n",
    "    docked_summary = docked_summary.rename(columns={\"員編\": \"五碼\"})\n",
    "    docked_summary = docked_summary.merge(ppl_schema_df, left_on='五碼', right_on='貼標ID', how='left')\n",
    "    docked_summary['type'] = 'Docked'\n",
    "    docked_summary['box'] = 0  # 其他種類才用到box，收發資料皆為0\n",
    "    docked_summary['total_pcs'] = 0  # 其他種類才用到orders，收發資料皆為0\n",
    "    docked_summary = docked_summary[['員編', 'type', 'total_pcs', 'box', 'INbound ID', '收發時間']]\n",
    "    docked_summary.columns = ['operator', 'type', 'total_pcs', 'box', 'orders', 'inbound_date']  # 合併資料統一要這幾個欄位\n",
    "    \n",
    "    print(docked_summary.head())\n",
    "    time3_3 = time.time()\n",
    "    print('Checkpoint 3-3 docked_summary SUCCEED     Spend {:.2f} seconds'.format(time3_3 - time3_2))\n",
    "\n",
    "    # 檔案4. print_summary: 如果有檔案，直接讀取過去檔案；反之則執行processing.take_month_data取得資料\n",
    "    print_df = get_everyday_print_data(day, gs)\n",
    "    print_df = print_df[[\"印標人員\", \"DATE\"]]\n",
    "    print_df['印標人員'] = print_df['印標人員'].apply(lambda x : str(x).replace(\"x\", \"0\").replace(\"X\", \"0\"))\n",
    "    print_df['印標人員'] = [str(i).replace(\"''\", \"\") for i in print_df['印標人員']]\n",
    "#     print_df['印標人員'] = print_df['印標人員'].astype('float').astype(\"int\").astype(\"str\")\n",
    "    print_summary = print_df.merge(ppl_schema_df, left_on='印標人員', right_on='貼標ID', how='left')\n",
    "    print_summary = print_summary[print_summary['員編'].notnull()]\n",
    "    print_summary['type'] = 'Print'\n",
    "    print_summary['box'] = 0  # 其他種類才用到box，印標資料皆為0\n",
    "    print_summary['total_pcs'] = 0  # 其他種類才用到orders，印標資料皆為0\n",
    "    print_summary['orders'] = 1  # 每個orders = 1\n",
    "    print_summary = print_summary[['員編', 'type', 'total_pcs', 'box', 'orders', 'DATE']]\n",
    "    print_summary.columns = ['operator', 'type', 'total_pcs', 'box', 'orders', 'inbound_date']  # 合併資料統一要這幾個欄位\n",
    "    print(print_summary.head())\n",
    "    time3_4 = time.time()\n",
    "    print('Checkpoint 3-4 print_df SUCCEED           Spend {:.2f} seconds'.format(time3_4 - time3_3))\n",
    "\n",
    "    ib_gsheet = gs.open_by_url(IB_gdoc.SCOPES).worksheet(IB_gdoc.SAMPLE_RANGE_NAME)\n",
    "    ib_df = pd.DataFrame(ib_gsheet.get_all_records())\n",
    "    ib_df[\"inbound_date\"] = pd.to_datetime(ib_df[\"inbound_date\"], errors='coerce')\n",
    "    ib_df[\"DATE\"] = ib_df[\"inbound_date\"].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    ib_df = ib_df[ib_df[\"DATE\"] == day]\n",
    "    ib_df.drop(columns='DATE')\n",
    "\n",
    "    ib_df = ib_df.append(tag_summary)\n",
    "    ib_df = ib_df.append(docked_summary)\n",
    "    ib_df = ib_df.append(print_summary)\n",
    "\n",
    "    ib_df.to_excel(inb_pics_file_path_new, index=False)\n",
    "    time3_5 = time.time()\n",
    "    print('Checkpoint 3-5 add to excel SUCCEED       Spend {:.2f} seconds'.format(time3_5 - time3_4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 4: 輸入資料格式統一\n",
    "# Checkpoint 4-1: IB_production\n",
    "def read_ibs(inb_pics_file_path_new, id_name_dic):\n",
    "    '''\n",
    "    read inbound PICS 的資料 (excel)\n",
    "    input:\n",
    "    1. inb_pics_file_path_new\n",
    "    2. id_name_dic: 名字對應到 id\n",
    "    '''\n",
    "    inb_pic_df = pd.read_excel(inb_pics_file_path_new, parse_dates=['inbound_date'])\n",
    "    inb_pic_df = inb_pic_df.rename(columns={'inbound_date': 'create_date'})\n",
    "    inb_pic_df = inb_pic_df[inb_pic_df['operator'].notnull()]  # 排除 operator 為空的列\n",
    "    inb_pic_df['operator'] = inb_pic_df['operator'].str.lower()  # 員編轉小寫\n",
    "    inb_pic_df['name'] = inb_pic_df['operator'].map(id_name_dic)  # 利用 id 轉名字\n",
    "    inb_pic_df = inb_pic_df[['name', 'operator', 'type', 'create_date', 'total_pcs', 'box', 'orders']]\n",
    "    inb_pic_df = inb_pic_df.rename(columns={'total_pcs': 'pcs', 'create_date': 'create_time'})\n",
    "    print(inb_pic_df.head())\n",
    "    return inb_pic_df[['name', 'operator', 'type', 'create_time', 'pcs', 'box', 'orders']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 4-2: OB_production\n",
    "def read_obs(id_name_dic, pda_id_dic, gs, day):\n",
    "    '''\n",
    "    read oubound / inv PICS 的資料 (excel)\n",
    "    input:\n",
    "    1. path_name : PICS 資料連結\n",
    "    2. name_id_dic: 名字對應到 id\n",
    "    read oubound / inv PICS 的資料 (csv)\n",
    "    因為資料欄位名稱不一樣，所以才要分開讀\n",
    "    '''\n",
    "    \n",
    "    awb_gsheet = gs.open_by_url(AWB_gdoc.SCOPES).worksheet(AWB_gdoc.SAMPLE_RANGE_NAME)\n",
    "    ob_gsheet = gs.open_by_url(OB_gdoc.SCOPES).worksheet(OB_gdoc.SAMPLE_RANGE_NAME)\n",
    "    ob_pic_df = pd.DataFrame(ob_gsheet.get_all_records()).append(pd.DataFrame(awb_gsheet.get_all_records()))\n",
    "    ob_pic_df['create_time'] = pd.to_datetime(ob_pic_df['create_time'], errors='coerce')\n",
    "#     print(ob_pic_df['create_time'].unique())\n",
    "    ob_pic_df[\"DATE\"] = ob_pic_df[\"create_time\"].dt.strftime('%Y-%m-%d')\n",
    "    ob_pic_df = ob_pic_df[ob_pic_df[\"DATE\"] == day]\n",
    "    ob_pic_df.drop(columns='DATE')\n",
    "    \n",
    "    ob_pic_df['workers'] = ob_pic_df['workers'].str.lower().astype('str')\n",
    "    ob_pic_df['type'] = ob_pic_df['type'].map({'1_picking': 'Picking', '3_packing': 'Packing', '4_awb': 'AWB'})\n",
    "\n",
    "    def get_operator(worker):\n",
    "        if 'sp' not in worker and worker in pda_id_dic:\n",
    "            return pda_id_dic[worker]\n",
    "        else:\n",
    "            return worker\n",
    "    ob_pic_df['operator'] = ob_pic_df['workers'].apply(get_operator)  # 如果workers是員編就輸出員編，是PDA帳號就轉成員編\n",
    "    ob_pic_df['name'] = ob_pic_df['operator'].map(id_name_dic)\n",
    "    ob_pic_df['box'] = 0\n",
    "    ob_pic_df['orders'] = 0\n",
    "    print(ob_pic_df.head())\n",
    "    return ob_pic_df[['name', 'operator', 'type', 'create_time', 'pcs', 'box', 'orders']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 4-3: INV_production\n",
    "def read_inv(id_name_dic, gs, day):\n",
    "    '''\n",
    "    read oubound / inv PICS 的資料 (excel)\n",
    "    input:\n",
    "    1. path_name: PICS 資料連結\n",
    "    2. name_id_dic: 名字對應到 id\n",
    "    read oubound / inv PICS 的資料 (csv)\n",
    "    因為資料欄位名稱不一樣，所以才要分開讀\n",
    "    '''\n",
    "    \n",
    "    inv_gsheet = gs.open_by_url(INV_gdoc.SCOPES).worksheet(INV_gdoc.SAMPLE_RANGE_NAME)\n",
    "    inv_pic_df = pd.DataFrame(inv_gsheet.get_all_records())\n",
    "    inv_pic_df['create_date'] = pd.to_datetime(inv_pic_df['create_date'], errors='coerce')\n",
    "    \n",
    "    inv_pic_df[\"DATE\"] = inv_pic_df[\"create_date\"].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    inv_pic_df = inv_pic_df[inv_pic_df[\"DATE\"] == day]\n",
    "    inv_pic_df.drop(columns='DATE')\n",
    "    \n",
    "    inv_pic_df = inv_pic_df[inv_pic_df['operator'].notnull()]  # 排除 operator 為空的列\n",
    "    inv_pic_df['operator'] = inv_pic_df['operator'].str.lower()  # 員編轉小寫\n",
    "    inv_pic_df['type'] = np.where(inv_pic_df['type'] == 'Cycle_count', 'Cyclecount', inv_pic_df['type'])  # type 字串轉換\n",
    "    inv_pic_df['name'] = inv_pic_df['operator'].map(id_name_dic)  # 利用 id 轉名字\n",
    "    inv_pic_df['box'] = 0\n",
    "    inv_pic_df['orders'] = 0\n",
    "    inv_pic_df = inv_pic_df.rename(columns={'create_date': 'create_time'})\n",
    "    print(inv_pic_df.head())\n",
    "    return inv_pic_df[['name', 'operator', 'type', 'create_time', 'pcs', 'box', 'orders']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 4-4: 將IB_production、OB_production、INV_production資料合併，得到whole_df\n",
    "def get_whole_df(ib_df, inv_df, ob_df):\n",
    "    '''\n",
    "    將ib_df、inv_df、ob_df合併\n",
    "    input: ib_df, inv_df, ob_df\n",
    "    output: 合併後的資料whole_df\n",
    "    '''\n",
    "    whole_df = pd.concat([ib_df, inv_df, ob_df])\n",
    "    whole_df['create_time'] = pd.to_datetime(whole_df['create_time'], errors='coerce')  # 轉不了日期就跳過\n",
    "\n",
    "    whole_df.dropna(how='any', inplace=True)\n",
    "    whole_df = whole_df[whole_df['create_time'].dt.date != datetime.date(1899, 12, 30)]\n",
    "    whole_df.sort_values(['create_time'], inplace=True)\n",
    "    # 'total_pcs'直接列出之後計算IPH的Productivity，'Arrived', 'Docked' 使用orders計算，'Putaway'使用box計算，其他皆使用pcs計算\n",
    "    whole_df['total_pcs'] = np.where(\n",
    "        whole_df['type'].isin(['Arrived', 'Docked', 'Print']), whole_df['orders'],\n",
    "        np.where(whole_df['type'] == 'Putaway', whole_df['box'], whole_df['pcs']))\n",
    "    print(whole_df.head())\n",
    "    return whole_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 5-1: 將whole_df、punch_df合併，得到merge_df\n",
    "def get_merge_df(whole_df, punch_df):\n",
    "    '''\n",
    "    將whole_df、punch_df合併，並判斷whole_df的create time是否在punch_df打卡的時段\n",
    "    input: whole_df, punch_df\n",
    "    output: merge_df\n",
    "    '''\n",
    "    \n",
    "    whole_df.sort_values('create_time', inplace=True)\n",
    "    punch_df.sort_values('created_time', inplace=True)\n",
    "    \n",
    "    merge_df = pd.merge_asof(\n",
    "        whole_df, punch_df.drop('name', axis=1),\n",
    "        left_on=\"create_time\", right_on=\"created_time\",\n",
    "        left_by=\"operator\", right_by=\"ID\", direction='backward')\n",
    "    merge_df = merge_df.rename(columns={'type_x': 'type', 'type_y': 'punch_type'})\n",
    "    merge_df['punch_type'] = merge_df['punch_type'].astype('str')\n",
    "    merge_df['merge_type'] = merge_df['punch_type'].str.replace('_4floor', '')\n",
    "    merge_df['valid_time'] = (merge_df['create_time'] >= merge_df['created_time']) & (merge_df['create_time'] <= merge_df['end_time'])\n",
    "    merge_df['valid_type'] = (merge_df['type'].values == merge_df['merge_type'].values) & merge_df['valid_time']\n",
    "    merge_df['Check Result'] = np.where(merge_df['valid_time'].values,\n",
    "                                        np.where(merge_df['valid_type'].values, 'Correct', 'Wrong Station'),\n",
    "                                        'No data')\n",
    "    merge_df['created_time'] = np.where(merge_df['Check Result'].values == 'No data',\n",
    "                                        np.datetime64('NaT'),\n",
    "                                        merge_df['created_time'].values)\n",
    "    merge_df['end_time'] = np.where(merge_df['Check Result'].values == 'No data',\n",
    "                                    np.datetime64('NaT'),\n",
    "                                    merge_df['end_time'].values)\n",
    "    merge_df['print_label'] = np.where(merge_df['Check Result'].values == 'Wrong Station',\n",
    "                                       merge_df['revised station'].values,\n",
    "                                       np.nan)\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 5-2: 將merge_df依各種工作種類合併(位於calculate_score.py)\n",
    "def get_valid_csv(merge_df, cat_name_checked, day):\n",
    "    '''\n",
    "    將5-1 merge_df的結果依不同cat_type分別儲存成csv檔\n",
    "    input:\n",
    "    1. merge_df\n",
    "    2. cat_name_checked: 目前不分樓層\n",
    "    '''\n",
    "    valid_whole_df = merge_df[['name', 'operator', 'type', 'create_time', 'pcs', 'box', 'orders', 'total_pcs',\n",
    "                               'Check Result', 'created_time', 'end_time', 'print_label']]\n",
    "    for cat in cat_name_checked:\n",
    "        cat_df = valid_whole_df[valid_whole_df['type'] == cat]\n",
    "        if not os.path.exists(\"Output/incentive_checked/{}\".format(day)):\n",
    "            os.makedirs(\"Output/incentive_checked/{}\".format(day))\n",
    "        cat_df.to_csv('Output/incentive_checked/{}/{}.csv'.format(day, cat), encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 6: 計算productivity_agent\n",
    "def get_prod_agent_score(cat_name, productivity_varable, whole_df, punch_df, agent_output_path):\n",
    "    '''\n",
    "    計算Agent的Productivity Score\n",
    "    input:\n",
    "    1. cat_name: 工作type的list\n",
    "    2. productivity_varable: 每種工作type的IPH績效\n",
    "    3. whole_df: 結合IB、OB、INV的資料\n",
    "    4. punch_df: 整理後打卡記錄表\n",
    "    output: 計算績效的DataFrame\n",
    "    '''\n",
    "    # 1. punch_ids人員資料\n",
    "    punch_ids = punch_df[['ID', 'name', 'role', 'class', 'group']].drop_duplicates().set_index('ID').sort_index()\n",
    "    merge_df = get_merge_df(whole_df, punch_df)\n",
    "    merge_df['type'] = np.where(merge_df['punch_type'].str.contains('_4floor'),\n",
    "                                merge_df['punch_type'], merge_df['type'])\n",
    "    punch_df['DL'] = punch_df['type'].notnull()  # 有沒有對應的cat_type\n",
    "\n",
    "    # 2. DL_count工作時數及有在cat_type的時間比例\n",
    "    DL_count = pd.crosstab(punch_df['ID'], punch_df['DL'], values=punch_df['hour'], aggfunc=np.sum)\n",
    "    DL_count.fillna(0, inplace=True)\n",
    "    DL_count.columns = ['not_DL', 'DL']\n",
    "    DL_count['total'] = DL_count['DL'].values + DL_count['not_DL'].values\n",
    "    DL_count['DL%'] = DL_count['DL'].values / DL_count['total'].values\n",
    "    DL_count = DL_count[['DL', 'not_DL',  # 有cat_type的工作時數、沒有cat_type的工作時數\n",
    "                         'total', 'DL%']]  # 總時數、有cat_type的工作時數的比例\n",
    "\n",
    "    # 3. pcs_count完成數量資訊\n",
    "    pcs_count = pd.crosstab(merge_df['operator'], merge_df['type'], values=merge_df['total_pcs'], aggfunc=np.sum).add_prefix('PCS_')\n",
    "    for cat in cat_name:\n",
    "        if 'PCS_{}'.format(cat) not in pcs_count.columns:\n",
    "            print('whole_df 無 {} 資料'.format(cat))\n",
    "            pcs_count['PCS_{}'.format(cat)] = 0\n",
    "    pcs_count = pcs_count[['PCS_{}'.format(cat) for cat in cat_name]]\n",
    "\n",
    "    # 4. hour_count工作時數資訊\n",
    "    hour_count = pd.crosstab(punch_df['ID'], punch_df['type'], values=punch_df['hour'], aggfunc=np.sum).add_prefix('Hour_')\n",
    "    for cat in cat_name:\n",
    "        if 'Hour_{}'.format(cat) not in hour_count.columns:\n",
    "            hour_count['Hour_{}'.format(cat)] = 0\n",
    "    \n",
    "    hour_count = hour_count[['Hour_{}'.format(cat) for cat in cat_name]]\n",
    "    \n",
    "    # productivity_table合併punch_ids, DL_count, pcs_count, hour_count\n",
    "    productivity_table = punch_ids.merge(DL_count, left_index=True, right_index=True, how='left')\\\n",
    "                                  .merge(pcs_count, left_index=True, right_index=True, how='left')\\\n",
    "                                  .merge(hour_count, left_index=True, right_index=True, how='left')\n",
    "    # 計算IPH分數: Hour = 0就是0，不然就是PCS/Hour\n",
    "    for cat in cat_name:\n",
    "        productivity_table['IPH_{}'.format(cat)] = np.where(productivity_table['Hour_{}'.format(cat)] == 0, 0,\n",
    "                                                            productivity_table['PCS_{}'.format(cat)] / productivity_table['Hour_{}'.format(cat)])\n",
    "    for cat in cat_name:\n",
    "        productivity_table['HR%_{}'.format(cat)] = productivity_table['Hour_{}'.format(cat)] / productivity_table['DL']\n",
    "\n",
    "    # IPH與目標的差距\n",
    "    for cat in cat_name:\n",
    "        productivity_table[cat] = productivity_table['IPH_{}'.format(cat)] / productivity_varable[cat]\n",
    "\n",
    "    # 計算Productivity Score\n",
    "    scores = pd.DataFrame()\n",
    "    for cat in cat_name:\n",
    "        scores[cat] = productivity_table[cat].values * productivity_table['HR%_{}'.format(cat)].values\n",
    "    scores['Productivity Score'] = scores.sum(axis=1)\n",
    "    scores.index = productivity_table.index\n",
    "\n",
    "    # 把Productivity Score合併至productivity_table\n",
    "    productivity_table = productivity_table.merge(scores[['Productivity Score']], left_index=True, right_index=True)\n",
    "    productivity_table.fillna(0, inplace=True)\n",
    "    productivity_table.reset_index(inplace=True)\n",
    "    productivity_table.to_excel(agent_output_path, index=False)\n",
    "    return productivity_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 7: 計算productivity_TL\n",
    "def get_prod_TL_score(productivity_varable, team_prod_dict, whole_df, punch_df, tl_output_path):\n",
    "    '''\n",
    "    計算Team Lead的Productivity Score\n",
    "    Team Lead: 只要打卡紀錄function_name出現過MGMT即視為Team Lead，但只計算每次打卡期間超過30分鐘的打卡\n",
    "    input:\n",
    "    1. productivity_varable: s每種工作type的IPH績效\n",
    "    3. whole_df: 結合IB、OB、INV的資料\n",
    "    4. punch_df: 整理後打卡記錄表\n",
    "    output: 計算績效的DataFrame\n",
    "    '''\n",
    "    merge_df = get_merge_df(whole_df, punch_df)\n",
    "    merge_df['type'] = np.where(merge_df['punch_type'].str.contains('_4floor'), merge_df['punch_type'], merge_df['type'])\n",
    "    iph = merge_df.groupby(['ID', 'type', 'created_time', 'end_time', 'hour'])['total_pcs'].agg(np.sum).reset_index()\\\n",
    "                  .rename(columns={'sum': 'total_pcs'})\n",
    "    iph['function'] = iph['type'].map(team_prod_dict)\n",
    "\n",
    "    def prod_ratio_calculate(iph, function, start, end):\n",
    "        iph_ckeck = iph[(iph['function'].values == function) &\n",
    "                        (iph['created_time'].values <= end) &  # 在該段時間內該cat_type的站點打卡\n",
    "                        (iph['end_time'].values >= start)]\\\n",
    "                        .groupby(['ID', 'type'])[['hour', 'total_pcs']].agg(np.sum).reset_index()\n",
    "        iph_ckeck['hour'] = np.where(iph_ckeck['hour'].values == 0, 0.008333, iph_ckeck['hour'].values)  # 0分鐘的資料在此算30秒(0.008333小時)\n",
    "        iph_ckeck['iph'] = iph_ckeck['total_pcs'].values / iph_ckeck['hour'].values\n",
    "        iph_ckeck['meet_goal'] = np.where(iph_ckeck['iph'].values >= iph_ckeck['type'].map(productivity_varable), 1, 0)\n",
    "        return pd.Series([np.sum(iph_ckeck['meet_goal']),\n",
    "                          iph_ckeck.shape[0]])\n",
    "    \n",
    "    # 1. team_df：以每次打卡記錄計算\n",
    "    team_df = punch_df[(punch_df['function_name'] == 'MGMT') & (punch_df['min'] >= 30)]  # 只要function_name有出現過MGMT就算Team Lead，只計算控場超過30分鐘的資料\n",
    "    team_df[['arrive_thres', 'count']] = team_df.apply(lambda row: prod_ratio_calculate(iph, row['function'], row['created_time'], row['end_time']), axis=1)\n",
    "    team_df['prod_hour_ratio'] = np.where(team_df['count'] == 0, 0, team_df['arrive_thres'].values / team_df['count'].values)\n",
    "\n",
    "    # 2. team_df_day：以每天打卡記錄計算\n",
    "    team_df_day = team_df.groupby(['ID', 'name', 'date', 'function'])[['hour', 'arrive_thres', 'count']].agg(np.sum).reset_index()\n",
    "    team_df_day['prod_day_ratio'] = np.where(team_df_day['count'] == 0, 0, team_df_day['arrive_thres'].values / team_df_day['count'].values)\n",
    "\n",
    "    # 3. productivity_tl：該月每個team lead負責控場天數及平均達標率（若一天有兩種控場，算兩天）\n",
    "    productivity_tl = team_df_day.groupby(['ID', 'name'])['prod_day_ratio'].agg(['count', np.mean]).reset_index()\n",
    "    productivity_tl = productivity_tl.rename(columns={'count': 'days_on_duty', 'mean': 'TL_produtivity_score'})\n",
    "\n",
    "    # 4. productivity_team_function：該月每個team lead每天控場達標率\n",
    "    productivity_team_function = pd.crosstab(\n",
    "        [team_df_day['ID'], team_df_day['name'], team_df_day['function']],\n",
    "        team_df_day['date'],\n",
    "        values=team_df_day['prod_day_ratio'], aggfunc='mean')\n",
    "    productivity_team_function['date_on_duty'] = productivity_team_function.count(axis=1)\n",
    "    productivity_team_function.reset_index(inplace=True)\n",
    "\n",
    "    with pd.ExcelWriter(tl_output_path) as writer:\n",
    "        team_df.to_excel(writer, sheet_name='team_df', index=False, encoding=\"utf_8_sig\")\n",
    "        team_df_day.to_excel(writer, sheet_name='team_df_day', index=False, encoding=\"utf_8_sig\")\n",
    "        productivity_tl.to_excel(writer, sheet_name='productivity_tl', index=False, encoding=\"utf_8_sig\")\n",
    "        productivity_team_function.to_excel(writer, sheet_name='productivity_team_function', index=False, encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 8: 將merge_df進行validation，產出 valid_whole_df\n",
    "def get_valid_whole_df(merge_df, day):\n",
    "    '''\n",
    "    將5-1的 merge_df 按照以下規則進行篩選：\n",
    "    1. 打卡時間位於 punch starting time and punch ending time\n",
    "    2. RT_putaway 和 Putaway 為 1. 之例外 \n",
    "    '''\n",
    "\n",
    "    merge_df[\"keep\"] = merge_df[\"valid_type\"]\n",
    "\n",
    "    for index, row in merge_df.iterrows():\n",
    "        if row[\"type\"] == \"Putaway\" and row[\"merge_type\"] == \"RT_putaway\":\n",
    "            merge_df.loc[index, \"keep\"] = True\n",
    "        elif row[\"type\"] == \"RT_putaway\" and row[\"merge_type\"] == \"Putaway\":\n",
    "            merge_df.loc[index, \"keep\"] = True\n",
    "\n",
    "    valid_whole_df = merge_df.copy()\n",
    "    valid_whole_df = valid_whole_df[valid_whole_df[\"keep\"]]\n",
    "    valid_whole_df = valid_whole_df[['name', 'operator', 'type', 'create_time', 'pcs', 'box', 'orders', 'total_pcs']]\n",
    "    valid_whole_df.to_csv(\"tmp_output/valid_whole_df/valid_whole_df_{}.csv\".format(day), encoding=\"utf_8_sig\", index=False)\n",
    "\n",
    "    return valid_whole_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_score_to_gsheet(df, gs, day):\n",
    "    new_score_df = df[[\"ID\", \"name\", \"Productivity Score\"]]\n",
    "    score_gsheet = gs.open_by_url(Score_gdoc.SCOPES).worksheet(Score_gdoc.SAMPLE_RANGE_NAME)\n",
    "    score_df = pd.DataFrame(score_gsheet.get_all_records())\n",
    "    score_df = pd.merge(score_df, new_score_df, left_on=[\"ID\", \"name\"], right_on=[\"ID\", \"name\"], how=\"outer\")\n",
    "    \n",
    "    score_df = score_df.rename(columns = {\"Productivity Score\": day})\n",
    "    score_df = score_df.fillna(0)\n",
    "    \n",
    "    score_gsheet.update([score_df.columns.values.tolist()] + score_df.values.tolist())\n",
    "\n",
    "def movefileAndPush():\n",
    "    try:\n",
    "#         subprocess.run(['git','config','--global','user.email','test@gmail.com'])\n",
    "        subprocess.run(['git','add','-A'])\n",
    "        subprocess.run(['git','commit','-m','Daily update'])\n",
    "        subprocess.run(['git','push'])\n",
    "    except Exception as e:\n",
    "        print(\"Error occured :\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_everyday_tag_data(day, gs):\n",
    "    SAMPLE_RANGE_NAME = day.replace(\"-\", \"\")  # 抓幾月幾號的表，例如2021-06-01就抓20210601\n",
    "    columns = ['版標流水號', '貼標開始', '貼標結束', '是否結束', '花費時間', '貼標人數(人)', '貼標ID']\n",
    "    try:\n",
    "        tag_gsheet = gs.open_by_url(tag_gdoc.SCOPES).worksheet(SAMPLE_RANGE_NAME)\n",
    "        tag_df = pd.DataFrame(tag_gsheet.get_all_records())\n",
    "        tag_df.columns = columns\n",
    "        \n",
    "        tag_df['貼標開始'] = pd.to_datetime(tag_df['貼標開始'], errors='coerce')\n",
    "        tag_df[\"貼標結束\"] = pd.to_datetime(tag_df[\"貼標結束\"], errors='coerce')\n",
    "        tag_df.dropna(axis=0, inplace=True)\n",
    "        tag_df['operator'] = tag_df['貼標ID'].astype(\"str\").str.lower()\n",
    "        tag_df['貼標人數(人)'] = tag_df['貼標人數(人)'].astype('int')\n",
    "        print('get {} data'.format(day))\n",
    "    except:  # 該天無印標資料\n",
    "        print('g-doc no data: {}'.format(SAMPLE_RANGE_NAME))\n",
    "        tag_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    tag_df.to_csv(\"tmp_output/label_raw/label_raw_{}.csv\".format(day), encoding=\"utf_8_sig\")\n",
    "    return tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_no_data(day, gs):\n",
    "    check_points = [\n",
    "        \"Arrived\", \"AWB\", \"Counting\", \"Cyclecount\", \"Docked\", \n",
    "        \"Labeling\", \"Packing\", \"Picking\", \"Print\", \"Putaway\",\n",
    "        \"QC\", \"Received\", \"RT_picking\", \"RT_putaway\", \"RTS\"]\n",
    "    \n",
    "    no_data_dct = dict()\n",
    "    punch_dct = dict()\n",
    "    \n",
    "    for point in check_points:\n",
    "        file_path = \"Output/incentive_checked/{}/{}.csv\".format(day, point)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        no_data = len(df[df[\"Check Result\"] == \"No data\"])\n",
    "        wrong = len(df[df[\"Check Result\"] == \"Wrong Station\"])\n",
    "        correct = len(df[df[\"Check Result\"] == \"Correct\"])\n",
    "        \n",
    "        # 計算 no data 比例\n",
    "        if no_data + wrong + correct != 0:\n",
    "            no_data_rate = no_data / (no_data + wrong + correct)\n",
    "        else:\n",
    "            no_data_rate = 0\n",
    "        \n",
    "        # 計算打卡正確率\n",
    "        if wrong + correct != 0:\n",
    "            punch_correct_rate = correct / (wrong + correct)\n",
    "        else:\n",
    "            punch_correct_rate = 0\n",
    "            \n",
    "        no_data_dct[point] = {\"Checkpoint\": point, day: round(no_data_rate*100, 2)}\n",
    "        punch_dct[point] = {\"Checkpoint\": point, day: round(punch_correct_rate*100, 2)}\n",
    "        \n",
    "    no_data_df = pd.DataFrame.from_dict(no_data_dct, orient=\"index\")\n",
    "    no_data_gsheet = gs.open_by_url(Score_gdoc.SCOPES).worksheet(\"No Data%\")\n",
    "    record_df = pd.DataFrame(no_data_gsheet.get_all_records())\n",
    "    record_df = record_df.merge(no_data_df, how=\"inner\")\n",
    "    no_data_gsheet.update([record_df.columns.values.tolist()] + record_df.values.tolist())\n",
    "    \n",
    "    punch_rate_df = pd.DataFrame.from_dict(punch_dct, orient=\"index\")\n",
    "    punch_rate_gsheet = gs.open_by_url(Score_gdoc.SCOPES).worksheet(\"Punch Rate%\")\n",
    "    record_df = pd.DataFrame(punch_rate_gsheet.get_all_records())\n",
    "    record_df = record_df.merge(punch_rate_df, how=\"inner\")\n",
    "    punch_rate_gsheet.update([record_df.columns.values.tolist()] + record_df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_everyday_print_data(day, gs):\n",
    "    day_obj = datetime.datetime.strptime(day, '%Y-%m-%d')\n",
    "    SAMPLE_RANGE_NAME = \"{}/{}\".format(day_obj.month, day_obj.day) # 抓幾月幾號的表\n",
    "    cols = ['是否印標', '印標人員', 'Tracking ID', '尾碼', 'SKU ID', 'DATE']\n",
    "    try:\n",
    "        print_gsheet = gs.open_by_url(print_gdoc.SCOPES).worksheet(SAMPLE_RANGE_NAME)\n",
    "\n",
    "        print_df = pd.DataFrame(print_gsheet.get_all_values())\n",
    "        print_df = print_df.rename(columns={\n",
    "            print_df.columns[0]: cols[0],\n",
    "            print_df.columns[1]: cols[1],\n",
    "            print_df.columns[2]: cols[2],\n",
    "            print_df.columns[3]: cols[3], \n",
    "            print_df.columns[4]: cols[4], \n",
    "            print_df.columns[17]: cols[5], \n",
    "        })\n",
    "        print_df.filter(items=cols)\n",
    "        print_df = print_df[(print_df['是否印標'] == 'V') & (print_df['SKU ID'] != '不用印')]\n",
    "        print_df.drop_duplicates(subset=['Tracking ID'], keep='first', inplace=True)\n",
    "        print('get {} data'.format(day))\n",
    "    except:  # 該天無印標資料\n",
    "        print_df = pd.DataFrame(columns=cols)\n",
    "        print('g-doc no data: {}'.format(day))\n",
    "    \n",
    "    print_df.to_csv(\"tmp_output/print_raw/print_raw_{}.csv\".format(day), encoding=\"utf_8_sig\")\n",
    "    return print_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_foler(month_fullname):\n",
    "\n",
    "    if not os.path.exists(\"Output/{}\".format(month_fullname)):\n",
    "        os.makedirs(\"Output/{}\".format(month_fullname))\n",
    "    if not os.path.exists(\"Output/incentive_checked\"):\n",
    "        os.makedirs(\"Output/incentive_checked\")\n",
    "\n",
    "    # Output Files\n",
    "    if not os.path.exists(\"Output/{}/productivity_TL\".format(month_fullname)):\n",
    "        os.makedirs(\"Output/{}/productivity_TL\".format(month_fullname))\n",
    "    # Output Files\n",
    "    if not os.path.exists(\"Output/{}/productivity_agent\".format(month_fullname)):\n",
    "        os.makedirs(\"Output/{}/productivity_agent\".format(month_fullname))        \n",
    "    # Output Files\n",
    "    if not os.path.exists(\"Output/{}/productivity_TL_valid\".format(month_fullname)):\n",
    "        os.makedirs(\"Output/{}/productivity_TL_valid\".format(month_fullname))        \n",
    "    # Output Files\n",
    "    if not os.path.exists(\"Output/{}/productivity_agent_valid\".format(month_fullname)):\n",
    "        os.makedirs(\"Output/{}/productivity_agent_valid\".format(month_fullname))\n",
    "\n",
    "def tmp_output_folder():\n",
    "    if not os.path.exists(\"tmp_output/docked_raw/\"):\n",
    "        os.makedirs(\"tmp_output/docked_raw/\")\n",
    "    if not os.path.exists(\"tmp_output/label_raw/\"):\n",
    "        os.makedirs(\"tmp_output/label_raw/\")\n",
    "    if not os.path.exists(\"tmp_output/merge_df/\"):\n",
    "        os.makedirs(\"tmp_output/merge_df/\")\n",
    "    if not os.path.exists(\"tmp_output/print_raw/\"):\n",
    "        os.makedirs(\"tmp_output/print_raw/\")\n",
    "    if not os.path.exists(\"tmp_output/punch_df/\"):\n",
    "        os.makedirs(\"tmp_output/punch_df/\")\n",
    "    if not os.path.exists(\"tmp_output/valid_whole_df/\"):\n",
    "        os.makedirs(\"tmp_output/valid_whole_df/\")\n",
    "    if not os.path.exists(\"tmp_output/whole_df/\"):\n",
    "        os.makedirs(\"tmp_output/whole_df/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "#     yesterday = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "    yesterday = datetime.datetime.now()\n",
    "\n",
    "    day = yesterday.strftime(\"%Y-%m-%d\")\n",
    "    month = yesterday.strftime(\"%Y-%m\")\n",
    "\n",
    "    month_first_day = datetime.datetime.strptime(month, \"%Y-%m\")\n",
    "    month_num = str(month_first_day.month)  # 得到str月份\n",
    "    month_shortname = month_first_day.strftime(\"%b\")  # e.g. Jul, Jun\n",
    "    month_fullname = month_first_day.strftime(\"%B\")  # e.g. July, June\n",
    "\n",
    "    # Input Files\n",
    "    revise_station_name = 'Input/revise_station.xlsx'\n",
    "    inb_pics_file_path_new = 'Input/IB_production_new/IB_production_{}_new.xlsx'.format(day)  # IB_production增加印標、收發、貼標後會儲存在此，並做為之後計算的input\n",
    "\n",
    "    # Crate folder\n",
    "    output_foler(month_fullname)\n",
    "    tmp_output_folder()\n",
    "\n",
    "    tl_output_path = \"Output/{}/productivity_TL/productivity_TL_{}.xlsx\".format(month_fullname, day)\n",
    "    agent_output_path = \"Output/{}/productivity_agent/productivity_agent_{}.xlsx\".format(month_fullname, day)\n",
    "    tl_valid_output_path = \"Output/{}/productivity_TL_valid/productivity_TL_{}_valid.xlsx\".format(month_fullname, day)\n",
    "    agent_valid_output_path = \"Output/{}/productivity_agent_valid/productivity_agent_{}_valid.xlsx\".format(month_fullname, day)\n",
    "\n",
    "    # 獲得憑證\n",
    "    scope = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "    creds = Credentials.from_service_account_file(\"credentials.json\", scopes=scope)\n",
    "    gs = gspread.authorize(creds)\n",
    "\n",
    "    print(\"=\"*5 + \"Caculate {} Incentive\".format(day) + \"=\"*5)\n",
    "    time0 = time.time()\n",
    "    punch_df = read_punch_file(day, revise_station_name, gs)\n",
    "    punch_df.to_csv('tmp_output/punch_df/punch_df_{}.csv'.format(day), index=False, encoding=\"utf_8_sig\")\n",
    "    punch_df.dropna(subset=['created_time', 'end_time'], axis=0, inplace=True)\n",
    "\n",
    "    time1 = time.time()\n",
    "    print('Checkpoint 1 read_punch_file SUCCEED      Spend {:.2f} seconds'.format(time1 - time0))\n",
    "\n",
    "    name_id_dic, id_name_dic, pda_name_dic, pda_id_dic = read_human_data(gs)\n",
    "    time2 = time.time()\n",
    "    print('Checkpoint 2 read_human_data SUCCEED     Spend {:.2f} seconds'.format(time2 - time1))\n",
    "\n",
    "    add_data_in_inb(time2, gs, day, month_fullname, inb_pics_file_path_new)\n",
    "    time3 = time.time()\n",
    "    print('Checkpoint 3 add_data_in_inb SUCCEED      Spend {:.2f} seconds'.format(time3 - time2))\n",
    "\n",
    "    ib_df = read_ibs(inb_pics_file_path_new, id_name_dic)\n",
    "    time4_1 = time.time()\n",
    "    print('Checkpoint 4-1 ib_df SUCCEED              Spend {:.2f} seconds'.format(time4_1 - time3))\n",
    "\n",
    "    ob_df = read_obs(id_name_dic, pda_id_dic, gs, day)\n",
    "    time4_2 = time.time()\n",
    "    print('Checkpoint 4-2 ob_df SUCCEED              Spend {:.2f} seconds'.format(time4_2 - time4_1)) \n",
    "\n",
    "    inv_df = read_inv(id_name_dic, gs, day)\n",
    "    time4_3 = time.time()\n",
    "    print('Checkpoint 4-3 inv_df SUCCEED             Spend {:.2f} seconds'.format(time4_3 - time4_2))\n",
    "\n",
    "    whole_df = get_whole_df(ib_df, inv_df, ob_df)\n",
    "    whole_df.to_csv('tmp_output/whole_df/whole_df_{}.csv'.format(day), index=False, encoding=\"utf_8_sig\")\n",
    "    time4_4 = time.time()\n",
    "    print('Checkpoint 4-4 whole_df SUCCEED           Spend {:.2f} seconds'.format(time4_4 - time4_3))\n",
    "\n",
    "    time4 = time.time()\n",
    "    print('Checkpoint 4 whole_df SUCCEED             Spend {:.2f} seconds'.format(time4 - time3))\n",
    "\n",
    "    merge_df = get_merge_df(whole_df, punch_df)\n",
    "    merge_df.to_csv(\"tmp_output/merge_df/merge_df_{}.csv\".format(day), index=False, encoding=\"utf_8_sig\")\n",
    "    time5_1 = time.time()\n",
    "    print('Checkpoint 5-1 get_merge_df SUCCEED       Spend {:.2f} seconds'.format(time5_1 - time4))\n",
    "\n",
    "    get_valid_csv(merge_df, cat_name_checked, day)\n",
    "    time5_2 = time.time()\n",
    "    print('Checkpoint 5-2 get_valid_csv SUCCEED      Spend {:.2f} seconds'.format(time5_2 - time5_1))\n",
    "    time5 = time.time()\n",
    "    print('Checkpoint 5 SUCCEED   Spend {:.2f} seconds'.format(time5 - time4))\n",
    "\n",
    "\n",
    "    get_prod_agent_score(cat_name, productivity_varable, whole_df, punch_df, agent_output_path)\n",
    "    time6 = time.time()\n",
    "    print('Checkpoint 6 productivity_agent SUCCEED   Spend {:.2f} seconds'.format(time6 - time5))\n",
    "\n",
    "    get_prod_TL_score(productivity_varable, team_prod_dict, whole_df, punch_df, tl_output_path)\n",
    "    time7 = time.time()\n",
    "    print('Checkpoint 7 productivity_TL SUCCEED      Spend {:.2f} seconds'.format(time7 - time6))\n",
    "\n",
    "    valid_whole_df = get_valid_whole_df(merge_df, day)\n",
    "    valid_whole_df.dropna(axis=0, inplace=True)\n",
    "    time8 = time.time()\n",
    "    print('Checkpoint 8 get_valid_whole_df SUCCEED      Spend {:.2f} seconds'.format(time8 - time7))\n",
    "\n",
    "    scroe_df = get_prod_agent_score(cat_name, productivity_varable, valid_whole_df, punch_df, agent_valid_output_path)\n",
    "    time9 = time.time()\n",
    "    print('Checkpoint 9 productivity_valid_agent SUCCEED     Spend {:.2f} seconds'.format(time9 - time8))\n",
    "\n",
    "    get_prod_TL_score(productivity_varable, team_prod_dict, valid_whole_df, punch_df, tl_valid_output_path)\n",
    "    time10 = time.time()\n",
    "    print('Checkpoint 10 productivity_valid_TL SUCCEED        Spend {:.2f} seconds'.format(time10 - time9))\n",
    "\n",
    "    submit_score_to_gsheet(scroe_df, gs, day)\n",
    "    cal_no_data(day, gs)\n",
    "    movefileAndPush()\n",
    "    time11 = time.time()\n",
    "    print('Checkpoint 11 Update final score to gsheet        Spend {:.2f} seconds'.format(time11 - time10))\n",
    "    print('計算完成 共花費{:.2f}秒'.format(time11 - time0))\n",
    "    print(\"=\"*20+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Caculate 2022-06-15 Incentive=====\n",
      "Checkpoint 1 read_punch_file SUCCEED      Spend 23.86 seconds\n",
      "Checkpoint 2 read_human_data SUCCEED     Spend 4.15 seconds\n",
      "Checkpoint 3-1 人力資料_schema SUCCEED    Spend 2.64 seconds\n",
      "get 2022-06-15 data\n",
      "  operator      type  total_pcs  box  orders        inbound_date\n",
      "0   SP2907  Labeling      100.0    0       0 2022-06-15 08:07:46\n",
      "1   SP2907  Labeling       12.0    0       0 2022-06-15 08:12:14\n",
      "2   SP2907  Labeling       12.0    0       0 2022-06-15 08:13:39\n",
      "3   SP2907  Labeling       12.0    0       0 2022-06-15 08:14:33\n",
      "4   SP2907  Labeling       12.0    0       0 2022-06-15 08:15:18\n",
      "Checkpoint 3-2 tag_summary SUCCEED        Spend 12.57 seconds\n",
      "  operator    type  total_pcs  box  orders        inbound_date\n",
      "0  SP99113  Docked          0    0       1 2022-06-15 07:22:19\n",
      "1  SP99113  Docked          0    0       1 2022-06-15 07:22:31\n",
      "2  SP99113  Docked          0    0       2 2022-06-15 07:22:39\n",
      "3  SP99113  Docked          0    0       1 2022-06-15 07:22:43\n",
      "4  SP99113  Docked          0    0       1 2022-06-15 07:25:19\n",
      "Checkpoint 3-3 docked_summary SUCCEED     Spend 6.06 seconds\n",
      "get 2022-06-15 data\n",
      "  operator   type  total_pcs  box  orders         inbound_date\n",
      "0  SP99068  Print          0    0       1  2022-06-14 18:35:41\n",
      "1  SP99068  Print          0    0       1  2022-06-14 18:34:33\n",
      "2  SP99068  Print          0    0       1  2022-06-14 18:33:31\n",
      "3  SP99068  Print          0    0       1  2022-06-14 18:32:04\n",
      "4  SP99068  Print          0    0       1  2022-06-14 18:30:58\n",
      "Checkpoint 3-4 print_df SUCCEED           Spend 7.78 seconds\n",
      "Checkpoint 3-5 add to excel SUCCEED       Spend 18.34 seconds\n",
      "Checkpoint 3 add_data_in_inb SUCCEED      Spend 47.43 seconds\n",
      "  name operator      type         create_time  pcs  box  orders\n",
      "0  許瑋迪  sp99026  Received 2022-06-15 18:40:00   70    0       0\n",
      "1   周紅   sp1344        QC 2022-06-15 12:38:10    0    0       0\n",
      "2  陳怡君   sp3082   Putaway 2022-06-15 16:10:41    6    1       0\n",
      "3  姜甄萍   sp3577   Putaway 2022-06-15 09:37:17   30    1       0\n",
      "4  李威震   sp2858   Putaway 2022-06-15 10:20:18    3    1       0\n",
      "Checkpoint 4-1 ib_df SUCCEED              Spend 0.96 seconds\n",
      "        type         create_time  workers pcs        DATE operator name  box  \\\n",
      "47   Packing 2022-06-15 23:13:47  sp99121   4  2022-06-15  sp99121  劉家偉    0   \n",
      "120  Packing 2022-06-15 13:46:35   sp1549   2  2022-06-15   sp1549  邱淑娟    0   \n",
      "192  Packing 2022-06-15 11:26:20  sp99095   1  2022-06-15  sp99095  王瑞芳    0   \n",
      "234  Packing 2022-06-15 14:03:43   sp2857   3  2022-06-15   sp2857   羅杰    0   \n",
      "383  Packing 2022-06-15 09:24:53   sp0508   1  2022-06-15   sp0508  玉文壽    0   \n",
      "\n",
      "     orders  \n",
      "47        0  \n",
      "120       0  \n",
      "192       0  \n",
      "234       0  \n",
      "383       0  \n",
      "Checkpoint 4-2 ob_df SUCCEED              Spend 25.91 seconds\n",
      "    operator        type         create_time  pcs        DATE  name  box  \\\n",
      "96   sp99026  RT_picking 2022-06-15 10:18:40   18  2022-06-15   許瑋迪    0   \n",
      "388   sp2858  RT_putaway 2022-06-15 09:20:15    3  2022-06-15   李威震    0   \n",
      "411   sp0500  RT_putaway 2022-06-15 09:04:15    2  2022-06-15  陳氏秋賢    0   \n",
      "551   sp2858  RT_picking 2022-06-15 08:56:41    3  2022-06-15   李威震    0   \n",
      "703   sp3577  RT_putaway 2022-06-15 16:40:45    2  2022-06-15   姜甄萍    0   \n",
      "\n",
      "     orders  \n",
      "96        0  \n",
      "388       0  \n",
      "411       0  \n",
      "551       0  \n",
      "703       0  \n",
      "Checkpoint 4-3 inv_df SUCCEED             Spend 11.73 seconds\n",
      "     name operator   type         create_time pcs  box  orders total_pcs\n",
      "5456  蔡雯琪  sp99068  Print 2022-06-06 13:24:52   0    0       1         1\n",
      "5338  蔡雯琪  sp99068  Print 2022-06-12 11:01:07   0    0       1         1\n",
      "5339  蔡雯琪  sp99068  Print 2022-06-12 11:08:57   0    0       1         1\n",
      "5337  蔡雯琪  sp99068  Print 2022-06-12 12:06:04   0    0       1         1\n",
      "5340  蔡雯琪  sp99068  Print 2022-06-13 17:10:30   0    0       1         1\n",
      "Checkpoint 4-4 whole_df SUCCEED           Spend 0.14 seconds\n",
      "Checkpoint 4 whole_df SUCCEED             Spend 38.74 seconds\n",
      "Checkpoint 5-1 get_merge_df SUCCEED       Spend 0.36 seconds\n",
      "Checkpoint 5-2 get_valid_csv SUCCEED      Spend 0.30 seconds\n",
      "Checkpoint 5 SUCCEED   Spend 0.66 seconds\n",
      "whole_df 無 RTS 資料\n",
      "whole_df 無 RT_putaway_4floor 資料\n",
      "whole_df 無 Cyclecount 資料\n",
      "whole_df 無 Cyclecount_4floor 資料\n",
      "Checkpoint 6 productivity_agent SUCCEED   Spend 0.52 seconds\n",
      "Checkpoint 7 productivity_TL SUCCEED      Spend 0.42 seconds\n",
      "Checkpoint 8 get_valid_whole_df SUCCEED      Spend 1.77 seconds\n",
      "whole_df 無 RTS 資料\n",
      "whole_df 無 RT_putaway_4floor 資料\n",
      "whole_df 無 Cyclecount 資料\n",
      "whole_df 無 Cyclecount_4floor 資料\n",
      "Checkpoint 9 productivity_valid_agent SUCCEED     Spend 0.38 seconds\n",
      "Checkpoint 10 productivity_valid_TL SUCCEED        Spend 0.32 seconds\n",
      "Checkpoint 11 Update final score to gsheet        Spend 16.11 seconds\n",
      "計算完成 共花費134.37秒\n",
      "====================\n",
      "\n",
      "=====Caculate 2022-06-16 Incentive=====\n",
      "Checkpoint 1 read_punch_file SUCCEED      Spend 17.43 seconds\n",
      "Checkpoint 2 read_human_data SUCCEED     Spend 4.21 seconds\n",
      "Checkpoint 3-1 人力資料_schema SUCCEED    Spend 2.28 seconds\n",
      "get 2022-06-16 data\n",
      "  operator      type  total_pcs  box  orders        inbound_date\n",
      "0   SP0386  Labeling       16.0    0       0 2022-06-16 08:17:18\n",
      "1   SP0386  Labeling       40.0    0       0 2022-06-16 08:19:46\n",
      "2  SP99007  Labeling       12.0    0       0 2022-06-16 08:20:51\n",
      "3  SP99007  Labeling       36.0    0       0 2022-06-16 08:21:37\n",
      "4   SP0386  Labeling       16.0    0       0 2022-06-16 08:22:16\n",
      "Checkpoint 3-2 tag_summary SUCCEED        Spend 6.50 seconds\n",
      "  operator    type  total_pcs  box  orders        inbound_date\n",
      "0  SP99085  Docked          0    0       1 2022-06-16 08:34:50\n",
      "1  SP99085  Docked          0    0       1 2022-06-16 08:34:55\n",
      "2  SP99085  Docked          0    0       2 2022-06-16 08:35:24\n",
      "3  SP99085  Docked          0    0       1 2022-06-16 08:35:28\n",
      "4  SP99085  Docked          0    0       1 2022-06-16 08:44:21\n",
      "Checkpoint 3-3 docked_summary SUCCEED     Spend 7.15 seconds\n",
      "get 2022-06-16 data\n",
      "  operator   type  total_pcs  box  orders         inbound_date\n",
      "0   SP2949  Print          0    0       1  2022-06-15 16:38:14\n",
      "1   SP2949  Print          0    0       1  2022-06-15 16:36:06\n",
      "2   SP2949  Print          0    0       1  2022-06-15 16:30:45\n",
      "3   SP2949  Print          0    0       1  2022-06-15 16:30:08\n",
      "4   SP2949  Print          0    0       1  2022-06-15 16:26:55\n",
      "Checkpoint 3-4 print_df SUCCEED           Spend 9.28 seconds\n",
      "Checkpoint 3-5 add to excel SUCCEED       Spend 17.71 seconds\n",
      "Checkpoint 3 add_data_in_inb SUCCEED      Spend 42.93 seconds\n",
      "  name operator      type         create_time  pcs  box  orders\n",
      "0  陳靚萱   sp3341  Received 2022-06-16 17:32:45   10    0       0\n",
      "1  李雨萱   sp2771  Received 2022-06-16 09:07:54    2    0       0\n",
      "2  張智翔   sp2974  Counting 2022-06-16 15:30:56    3    0       0\n",
      "3  張奕興   sp2016   Putaway 2022-06-16 17:44:44  227    1       0\n",
      "4  石悠賢   sp0537   Putaway 2022-06-16 09:36:12    6    1       0\n",
      "Checkpoint 4-1 ib_df SUCCEED              Spend 0.97 seconds\n",
      "    type         create_time workers pcs        DATE operator name  box  \\\n",
      "69   AWB 2022-06-16 15:43:51  sp0527   1  2022-06-16   sp0527  陳佳妮    0   \n",
      "88   AWB 2022-06-16 15:22:09  sp0527   1  2022-06-16   sp0527  陳佳妮    0   \n",
      "253  AWB 2022-06-16 15:53:55  sp0527   1  2022-06-16   sp0527  陳佳妮    0   \n",
      "270  AWB 2022-06-16 13:46:56  sp0531   1  2022-06-16   sp0531  林暖仁    0   \n",
      "327  AWB 2022-06-16 15:26:59  sp0527   1  2022-06-16   sp0527  陳佳妮    0   \n",
      "\n",
      "     orders  \n",
      "69        0  \n",
      "88        0  \n",
      "253       0  \n",
      "270       0  \n",
      "327       0  \n",
      "Checkpoint 4-2 ob_df SUCCEED              Spend 24.86 seconds\n",
      "    operator        type         create_time  pcs        DATE name  box  \\\n",
      "51    sp0528  RT_picking 2022-06-16 10:17:26    2  2022-06-16  潘銳撫    0   \n",
      "54   sp99079  RT_picking 2022-06-16 11:14:30    6  2022-06-16  陳晉千    0   \n",
      "79   sp99100  RT_picking 2022-06-16 08:05:01    7  2022-06-16  許國勤    0   \n",
      "442  sp99080  Cyclecount 2022-06-16 16:28:49   34  2022-06-16  賴韻如    0   \n",
      "451  sp99080  Cyclecount 2022-06-16 17:33:41   15  2022-06-16  賴韻如    0   \n",
      "\n",
      "     orders  \n",
      "51        0  \n",
      "54        0  \n",
      "79        0  \n",
      "442       0  \n",
      "451       0  \n",
      "Checkpoint 4-3 inv_df SUCCEED             Spend 10.93 seconds\n",
      "     name operator   type         create_time pcs  box  orders total_pcs\n",
      "5992  陳映蓉   sp2949  Print 2022-06-15 15:46:58   0    0       1         1\n",
      "5991  陳映蓉   sp2949  Print 2022-06-15 15:47:15   0    0       1         1\n",
      "5990  陳映蓉   sp2949  Print 2022-06-15 15:49:12   0    0       1         1\n",
      "5989  陳映蓉   sp2949  Print 2022-06-15 15:49:41   0    0       1         1\n",
      "5988  陳映蓉   sp2949  Print 2022-06-15 15:53:43   0    0       1         1\n",
      "Checkpoint 4-4 whole_df SUCCEED           Spend 0.16 seconds\n",
      "Checkpoint 4 whole_df SUCCEED             Spend 36.91 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 5-1 get_merge_df SUCCEED       Spend 0.40 seconds\n",
      "Checkpoint 5-2 get_valid_csv SUCCEED      Spend 0.30 seconds\n",
      "Checkpoint 5 SUCCEED   Spend 0.70 seconds\n",
      "whole_df 無 RT_picking_4floor 資料\n",
      "whole_df 無 RT_putaway_4floor 資料\n",
      "whole_df 無 Cyclecount_4floor 資料\n",
      "Checkpoint 6 productivity_agent SUCCEED   Spend 0.49 seconds\n",
      "Checkpoint 7 productivity_TL SUCCEED      Spend 0.40 seconds\n",
      "Checkpoint 8 get_valid_whole_df SUCCEED      Spend 2.85 seconds\n",
      "whole_df 無 RT_picking_4floor 資料\n",
      "whole_df 無 RT_putaway_4floor 資料\n",
      "whole_df 無 Cyclecount_4floor 資料\n",
      "Checkpoint 9 productivity_valid_agent SUCCEED     Spend 0.37 seconds\n",
      "Checkpoint 10 productivity_valid_TL SUCCEED        Spend 0.33 seconds\n",
      "Checkpoint 11 Update final score to gsheet        Spend 13.13 seconds\n",
      "計算完成 共花費119.76秒\n",
      "====================\n",
      "\n",
      "=====Caculate 2022-06-17 Incentive=====\n",
      "Checkpoint 1 read_punch_file SUCCEED      Spend 18.41 seconds\n",
      "Checkpoint 2 read_human_data SUCCEED     Spend 4.31 seconds\n",
      "Checkpoint 3-1 人力資料_schema SUCCEED    Spend 2.72 seconds\n",
      "get 2022-06-17 data\n",
      "  operator      type  total_pcs  box  orders        inbound_date\n",
      "0  SP99007  Labeling       12.0    0       0 2022-06-17 08:05:11\n",
      "1  SP99007  Labeling       18.0    0       0 2022-06-17 08:05:27\n",
      "2  SP99007  Labeling       49.0    0       0 2022-06-17 08:08:14\n",
      "3   SP0386  Labeling       18.0    0       0 2022-06-17 08:08:51\n",
      "4   SP0386  Labeling       18.0    0       0 2022-06-17 08:09:16\n",
      "Checkpoint 3-2 tag_summary SUCCEED        Spend 9.43 seconds\n",
      "  operator    type  total_pcs  box  orders        inbound_date\n",
      "0   SP1749  Docked          0    0       1 2022-06-17 07:25:58\n",
      "1   SP1749  Docked          0    0       1 2022-06-17 07:27:15\n",
      "2   SP1749  Docked          0    0       1 2022-06-17 07:27:55\n",
      "3   SP1749  Docked          0    0       1 2022-06-17 07:29:02\n",
      "4   SP1749  Docked          0    0       1 2022-06-17 07:29:13\n",
      "Checkpoint 3-3 docked_summary SUCCEED     Spend 5.89 seconds\n",
      "get 2022-06-17 data\n",
      "  operator   type  total_pcs  box  orders         inbound_date\n",
      "0   SP2949  Print          0    0       1  2022-06-16 18:57:48\n",
      "1   SP2949  Print          0    0       1  2022-06-16 18:57:00\n",
      "2   SP2949  Print          0    0       1  2022-06-16 18:56:04\n",
      "3   SP2949  Print          0    0       1  2022-06-16 18:55:26\n",
      "4   SP2949  Print          0    0       1  2022-06-16 18:54:48\n",
      "Checkpoint 3-4 print_df SUCCEED           Spend 13.54 seconds\n",
      "Checkpoint 3-5 add to excel SUCCEED       Spend 18.20 seconds\n",
      "Checkpoint 3 add_data_in_inb SUCCEED      Spend 49.82 seconds\n",
      "  name operator      type         create_time  pcs  box  orders\n",
      "0  盤秋伶  sp99073  Received 2022-06-17 10:36:13    3    0       0\n",
      "1  盤秋伶  sp99073  Received 2022-06-17 17:10:31    2    0       0\n",
      "2  陳映蓉   sp2949  Received 2022-06-17 08:29:26    2    0       0\n",
      "3  陳映蓉   sp2949  Received 2022-06-17 17:59:57    4    0       0\n",
      "4  黃淑貞   sp1848   Putaway 2022-06-17 17:59:58    4    1       0\n",
      "Checkpoint 4-1 ib_df SUCCEED              Spend 0.98 seconds\n",
      "        type         create_time workers pcs        DATE operator name  box  \\\n",
      "79   Packing 2022-06-17 10:37:00  sp0999   1  2022-06-17   sp0999  鄭愛玲    0   \n",
      "110  Packing 2022-06-17 09:07:09  sp0520   1  2022-06-17   sp0520  馬典志    0   \n",
      "161  Packing 2022-06-17 12:38:32  sp1005   3  2022-06-17   sp1005  唐慧芳    0   \n",
      "178  Packing 2022-06-17 10:00:24  sp1748   5  2022-06-17   sp1748  李選聖    0   \n",
      "189  Packing 2022-06-17 15:38:39  sp0540   5  2022-06-17   sp0540  石恆努    0   \n",
      "\n",
      "     orders  \n",
      "79        0  \n",
      "110       0  \n",
      "161       0  \n",
      "178       0  \n",
      "189       0  \n",
      "Checkpoint 4-2 ob_df SUCCEED              Spend 27.11 seconds\n",
      "    operator        type         create_time  pcs        DATE name  box  \\\n",
      "6    sp99077  Cyclecount 2022-06-17 17:31:10   15  2022-06-17  王怡蓉    0   \n",
      "94    sp1743  RT_picking 2022-06-17 14:35:44   24  2022-06-17  戴清秀    0   \n",
      "144   sp0446  RT_picking 2022-06-17 14:14:25    3  2022-06-17  高智勇    0   \n",
      "171   sp1743  RT_putaway 2022-06-17 12:12:12   60  2022-06-17  戴清秀    0   \n",
      "179   sp1739  RT_putaway 2022-06-17 09:13:57    4  2022-06-17  温蘇蝶    0   \n",
      "\n",
      "     orders  \n",
      "6         0  \n",
      "94        0  \n",
      "144       0  \n",
      "171       0  \n",
      "179       0  \n",
      "Checkpoint 4-3 inv_df SUCCEED             Spend 11.00 seconds\n",
      "     name operator   type         create_time pcs  box  orders total_pcs\n",
      "6092  陳映蓉   sp2949  Print 2022-06-16 18:52:18   0    0       1         1\n",
      "6091  陳映蓉   sp2949  Print 2022-06-16 18:53:19   0    0       1         1\n",
      "6090  陳映蓉   sp2949  Print 2022-06-16 18:54:07   0    0       1         1\n",
      "6089  陳映蓉   sp2949  Print 2022-06-16 18:54:48   0    0       1         1\n",
      "6088  陳映蓉   sp2949  Print 2022-06-16 18:55:26   0    0       1         1\n",
      "Checkpoint 4-4 whole_df SUCCEED           Spend 0.20 seconds\n",
      "Checkpoint 4 whole_df SUCCEED             Spend 39.29 seconds\n",
      "Checkpoint 5-1 get_merge_df SUCCEED       Spend 0.89 seconds\n",
      "Checkpoint 5-2 get_valid_csv SUCCEED      Spend 0.77 seconds\n",
      "Checkpoint 5 SUCCEED   Spend 1.65 seconds\n",
      "whole_df 無 Counting 資料\n",
      "whole_df 無 RT_picking_4floor 資料\n",
      "whole_df 無 RT_putaway_4floor 資料\n",
      "whole_df 無 Cyclecount_4floor 資料\n",
      "Checkpoint 6 productivity_agent SUCCEED   Spend 0.73 seconds\n",
      "Checkpoint 7 productivity_TL SUCCEED      Spend 0.48 seconds\n",
      "Checkpoint 8 get_valid_whole_df SUCCEED      Spend 3.24 seconds\n",
      "whole_df 無 Counting 資料\n",
      "whole_df 無 RT_picking_4floor 資料\n",
      "whole_df 無 RT_putaway_4floor 資料\n",
      "whole_df 無 Cyclecount_4floor 資料\n",
      "Checkpoint 9 productivity_valid_agent SUCCEED     Spend 0.45 seconds\n",
      "Checkpoint 10 productivity_valid_TL SUCCEED        Spend 0.41 seconds\n",
      "Checkpoint 11 Update final score to gsheet        Spend 15.23 seconds\n",
      "計算完成 共花費134.03秒\n",
      "====================\n",
      "\n",
      "=====Caculate 2022-06-18 Incentive=====\n",
      "Checkpoint 1 read_punch_file SUCCEED      Spend 15.49 seconds\n",
      "Checkpoint 2 read_human_data SUCCEED     Spend 3.65 seconds\n",
      "Checkpoint 3-1 人力資料_schema SUCCEED    Spend 2.84 seconds\n",
      "get 2022-06-18 data\n",
      "  operator      type  total_pcs  box  orders        inbound_date\n",
      "0   SP2907  Labeling       30.0    0       0 2022-06-18 09:01:04\n",
      "1   SP0386  Labeling       30.0    0       0 2022-06-18 09:04:49\n",
      "2   SP2907  Labeling       20.0    0       0 2022-06-18 09:05:26\n",
      "3   SP0386  Labeling       10.0    0       0 2022-06-18 09:07:31\n",
      "4   SP2907  Labeling        8.0    0       0 2022-06-18 09:08:05\n",
      "Checkpoint 3-2 tag_summary SUCCEED        Spend 10.34 seconds\n",
      "Empty DataFrame\n",
      "Columns: [operator, type, total_pcs, box, orders, inbound_date]\n",
      "Index: []\n",
      "Checkpoint 3-3 docked_summary SUCCEED     Spend 5.55 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     main()\n",
    "    schedule.every().day.at(\"22:30\").do(main)\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(30) # wait one minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
